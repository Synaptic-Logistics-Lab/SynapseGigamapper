{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19208301",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROTGPS_PARENT_DIR = \"/home/shd-sun-lab/protgps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d52a6de-7949-4492-8fc2-c8867ec3a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(PROTGPS_PARENT_DIR) # append the path of protgps\n",
    "from argparse import Namespace\n",
    "import pickle\n",
    "import copy\n",
    "import yaml\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from p_tqdm import p_map\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import torch \n",
    "from captum.attr import LayerIntegratedGradients\n",
    "from captum.attr import visualization as viz\n",
    "import protpy\n",
    "from protpy import amino_acids as protpyAA\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "from protgps.utils.loading import get_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09240b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d547d1-8adb-46ba-8185-8f3a28351e60",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7379a5d3-a4e9-4af2-9793-46ec6a427155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHAT'S IN THE LOCAL CODE\n",
    "COMPARTMENTS = [\n",
    "    'transcriptional',\n",
    "    'chromosome',\n",
    "    'nuclear_pore_complex',\n",
    "    'nuclear_speckle', \n",
    "    'p-body', \n",
    "    'pml-bdoy', \n",
    "    'post_synaptic_density',\n",
    "    'stress_granule',\n",
    "    'nucleolus',\n",
    "    'cajal_body',\n",
    "    'rna_granule',\n",
    "    'cell_junction'\n",
    "]\n",
    "\n",
    "# WHAT'S IN THE COMMITTED CODE\n",
    "# ORDER WAS CHANGED AT SOME POINT!!! \n",
    "# USE THE ONE ON GITHUB\n",
    "# https://github.com/pgmikhael/nox/blob/1e5b963cbfdad23418a98c7c67a11c6431869cf6/nox/datasets/protein_compartments.py\n",
    "OLDCOMPS = [\n",
    "    \"nuclear_speckle\",\n",
    "    \"p-body\",\n",
    "    \"pml-bdoy\",\n",
    "    \"post_synaptic_density\",\n",
    "    \"stress_granule\",\n",
    "    \"chromosome\",\n",
    "    \"nucleolus\",\n",
    "    \"nuclear_pore_complex\",\n",
    "    \"cajal_body\",\n",
    "    \"rna_granule\",\n",
    "    \"cell_junction\",\n",
    "    \"transcriptional\"\n",
    "]\n",
    "\n",
    "def transform_y(y: torch.Tensor):\n",
    "    # get indices where y is one in, where y is a pytorch tensor\n",
    "    indices = torch.nonzero(y)\n",
    "    # convert indices from list1 to equivalent classes in list2\n",
    "    new_indices = torch.tensor([OLDCOMPS.index(COMPARTMENTS[i]) for i in indices])\n",
    "    # return binary tensor based on new indices\n",
    "    return torch.zeros(len(OLDCOMPS)).scatter_(0, new_indices, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6e36e82-407d-423b-9fcc-c66a44d39ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIPROT_ENTRY_URL = \"https://rest.uniprot.org/uniprotkb/O14983.fasta\"\n",
    "\n",
    "def get_organism(uni):\n",
    "    response= requests.get(f\"https://rest.uniprot.org/uniprotkb/O14983.json\").json()\n",
    "    if 'organism' in response:\n",
    "        return response['organism']['scientificName']\n",
    "    else:\n",
    "        return \"\"\n",
    "        \n",
    "def parse_fasta(f):\n",
    "    \"\"\"Parse fasta data\n",
    "\n",
    "    Args:\n",
    "        f (str): fasta data\n",
    "\n",
    "    Returns:\n",
    "        str: protein sequence\n",
    "    \"\"\"\n",
    "    _seq = \"\"\n",
    "    for _line in f.split(\"\\n\"):\n",
    "        if _line.startswith(\">\"):\n",
    "            continue\n",
    "        _seq += _line.strip()\n",
    "    return _seq\n",
    "\n",
    "\n",
    "def get_protein_fasta(uniprot):\n",
    "    \"\"\"Get protein info from uniprot\n",
    "\n",
    "    Args:\n",
    "        uniprot (str): uniprot\n",
    "    \"\"\"\n",
    "    fasta = requests.get(UNIPROT_ENTRY_URL.format(uniprot))\n",
    "    if fasta.status_code == 200:  # Success\n",
    "        sequence = parse_fasta(fasta.text)\n",
    "        return sequence\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "165f2091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#Test to see if it gets a sequence\n",
    "protein_id = \"O14983\"  # Example UniProt ID\n",
    "sequence = get_protein_fasta(protein_id)\n",
    "print(f\"Protein sequence for {protein_id}:\\n{sequence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9db6a7f8-195e-4ad2-ba17-98f069cc2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(snargs):\n",
    "    \"\"\"\n",
    "    Loads classifier model from args file\n",
    "    \"\"\"\n",
    "    modelpath = snargs.model_path\n",
    "    model = get_object(snargs.lightning_name, \"lightning\")(snargs)\n",
    "    model = model.load_from_checkpoint(\n",
    "        checkpoint_path = modelpath,\n",
    "        strict=not snargs.relax_checkpoint_matching,\n",
    "        **{\"args\": snargs},\n",
    "    )\n",
    "    return model, snargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d55001b-a120-4acd-9d02-7f07953bf3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_condensates(model, sequences, batch_size, round=True):\n",
    "    scores = []\n",
    "    for i in tqdm(range(0, len(sequences), batch_size), ncols=100):\n",
    "        batch = sequences[ i : (i + batch_size)]\n",
    "        with torch.no_grad():\n",
    "            out = model.model({\"x\": batch})    \n",
    "        s = torch.sigmoid(out['logit']).to(\"cpu\")\n",
    "        scores.append(s)\n",
    "    scores = torch.vstack(scores)\n",
    "    if round:\n",
    "        scores = torch.round(scores, decimals=3)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f71c9d47-7813-4e82-a0f9-42ba4dd3a2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_rows(df, cols):\n",
    "    rows_with_valid_seq_len = []\n",
    "    for i in range(len(df)):\n",
    "        if all([ len(df.iloc[i][c]) < 1800 for c in cols]):\n",
    "            rows_with_valid_seq_len.append(i)\n",
    "    return rows_with_valid_seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21f24a0-e320-4195-9f48-0bd48205aedb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Predictions on Additional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f49e94da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/shd-sun-lab/protgps/checkpoints/esm2/facebookresearch_esm_main\n",
      "Using cache found in /home/shd-sun-lab/protgps/checkpoints/esm2/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ESM hidden layers 6\n",
      "Using ESM hidden layers 6\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(**pickle.load(open(os.path.join(PROTGPS_PARENT_DIR, 'checkpoints/protgps/32bf44b16a4e770a674896b81dfb3729.args'),'rb')))\n",
    "args.pretrained_hub_dir = \"/home/shd-sun-lab/protgps/checkpoints/esm2\"\n",
    "args.model_path = \"/home/shd-sun-lab/protgps/checkpoints/protgps/32bf44b16a4e770a674896b81dfb3729epoch=26.ckpt\"  # Ensure this is set\n",
    "\n",
    "\n",
    "model = load_model(args)\n",
    "model = model[0]\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b9fde-1149-45d3-a54e-06cd9e4958c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Condensate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75386dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5480/5480 [00:00<00:00, 61739.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATASET CREATED FOR PROTEIN_CONDENSATES_COMBINED.\n",
      "Could not produce summary statement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5480/5480 [00:00<00:00, 117443.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV DATASET CREATED FOR PROTEIN_CONDENSATES_COMBINED.\n",
      "Could not produce summary statement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5480/5480 [00:00<00:00, 108922.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATASET CREATED FOR PROTEIN_CONDENSATES_COMBINED.\n",
      "Could not produce summary statement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load test dataset\n",
    "args.dataset_file_path = \"/home/shd-sun-lab/protgps/data/dataset.json\"\n",
    "train_dataset = get_object(args.dataset_name, \"dataset\")(args, \"train\")\n",
    "dev_dataset = get_object(args.dataset_name, \"dataset\")(args, \"dev\")\n",
    "test_dataset = get_object(args.dataset_name, \"dataset\")(args, \"test\")\n",
    "train_sequences = set(d['x'] for d in train_dataset.dataset+dev_dataset.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "081230c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"/home/shd-sun-lab/protgps/notebook/data/Condensate_data_idmapping_2023_11_04.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7da6b68c-1eb6-49e4-bcc4-2022fd3ae70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_ids = set()\n",
    "for rowid, row in data.iterrows():\n",
    "    if isinstance(row['Cluster members'],str):\n",
    "        entries = row['Cluster members'].split(\";\")\n",
    "        entries = [e.split(',')[0].strip() for e in entries]\n",
    "        protein_ids.update(entries)\n",
    "        cluster = row['From'].split(\"_\")[0]\n",
    "        protein_ids.add(cluster)\n",
    "    elif np.isnan(row['Cluster members']):\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9ebd8b4-cd79-426c-8ece-211580c279c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.037628889083862305,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 788355,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f54b95fcbb4387830ebb8a2a961d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/788355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sequences \u001b[38;5;241m=\u001b[39m \u001b[43mp_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_protein_fasta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprotein_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m protein2sequence \u001b[38;5;241m=\u001b[39m {p:s \u001b[38;5;28;01mfor\u001b[39;00m p,s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(protein_ids,sequences)}\n\u001b[1;32m      3\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(protein2sequence, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCondensate_data_idmapping_sequences.p\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/miniforge3/envs/protgps/lib/python3.8/site-packages/p_tqdm/p_tqdm.py:66\u001b[0m, in \u001b[0;36mp_map\u001b[0;34m(function, *iterables, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m ordered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     65\u001b[0m generator \u001b[38;5;241m=\u001b[39m _parallel(ordered, function, \u001b[38;5;241m*\u001b[39miterables, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 66\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniforge3/envs/protgps/lib/python3.8/site-packages/p_tqdm/p_tqdm.py:58\u001b[0m, in \u001b[0;36m_parallel\u001b[0;34m(ordered, function, *iterables, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m tqdm_func(map_func(function, \u001b[38;5;241m*\u001b[39miterables), total\u001b[38;5;241m=\u001b[39mlength, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m item\n\u001b[0;32m---> 58\u001b[0m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclear\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/protgps/lib/python3.8/site-packages/pathos/multiprocessing.py:144\u001b[0m, in \u001b[0;36mProcessPool._clear\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _pool \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__nodes \u001b[38;5;241m==\u001b[39m _pool\u001b[38;5;241m.\u001b[39m__nodes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwds \u001b[38;5;241m==\u001b[39m _pool\u001b[38;5;241m.\u001b[39m_kwds:\n\u001b[1;32m    143\u001b[0m     _pool\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 144\u001b[0m     \u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     __STATE\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/protgps/lib/python3.8/site-packages/multiprocess/pool.py:662\u001b[0m, in \u001b[0;36mPool.join\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (CLOSE, TERMINATE):\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn unknown state\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 662\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_worker_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_handler\u001b[38;5;241m.\u001b[39mjoin()\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_handler\u001b[38;5;241m.\u001b[39mjoin()\n",
      "File \u001b[0;32m~/miniforge3/envs/protgps/lib/python3.8/threading.py:1011\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1011\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1013\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniforge3/envs/protgps/lib/python3.8/threading.py:1027\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# already determined that the C code is done\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_stopped\n\u001b[0;32m-> 1027\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1028\u001b[0m     lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sequences = p_map(get_protein_fasta, list(protein_ids))\n",
    "protein2sequence = {p:s for p,s in zip(protein_ids,sequences)}\n",
    "pickle.dump(protein2sequence, open(\"Condensate_data_idmapping_sequences.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfcaf9b-6799-4db7-90be-da0c51fcee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_ids = [ p for p, s in protein2sequence.items() if s is not None ]\n",
    "sequences = [ protein2sequence[p] for p in protein_ids ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ee4564-1a2d-469b-ba44-63d32726fae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = predict_condensates(model, sequences, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cda104f-b0f8-4f8b-b524-ec34ebdbeec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = torch.vstack(scores)\n",
    "scores_round = torch.round(scores, decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64274df0-bed6-4a4e-9621-c72aaaf7cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_round = torch.load(\"scores_round.pt\")\n",
    "scores_round, protein_ids_scores = scores_round[\"scores\"], scores_round[\"protein_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc81f48-b720-4234-a966-8de236505c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_to_scores = {p:s for p,s in zip(protein_ids_scores,scores_round)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3868f9cf-4d4b-481c-ba42-d8bc0cda4993",
   "metadata": {},
   "outputs": [],
   "source": [
    "organisms = p_map(get_organism, protein_ids_scores)\n",
    "protein_ids_scores_to_organisms = {p:o for p,o in zip(protein_ids_scores, organisms)}\n",
    "pickle.dump(protein_ids_scores_to_organisms, open(\"protein_ids_scores_to_organisms.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7781bd-a97d-4454-a3c4-03119ee0e738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "results_df = defaultdict(list)\n",
    "with tqdm(total=len(data), ncols=100) as tqdm_bar:\n",
    "    for rowid, row in data.iterrows():\n",
    "        if isinstance(row['Cluster members'],str):\n",
    "            entries = row['Cluster members'].split(\";\")\n",
    "            entries = [e.split(',')[0].strip() for e in entries]\n",
    "            for entry in entries:\n",
    "                if entry in protein_to_scores:\n",
    "                    sequence = protein2sequence[entry]\n",
    "                    results_df[\"ProteinID\"].append(entry)\n",
    "                    results_df[\"Protein_Split\"].append(\"train\" if sequence in train_sequences else \"test\")\n",
    "                    results_df[\"Organism\"].append(protein_ids_scores_to_organisms[entry])\n",
    "                    results_df[\"original_row\"].append(rowid)\n",
    "                    results_df[\"gene_names\"].append(row[\"gene_names\"])\n",
    "                    results_df[\"split\"].append(row[\"split\"]) \n",
    "                    results_df[\"labels\"].append(row[\"labels\"])\n",
    "                    results_df[\"From\"].append(row[\"From\"])\n",
    "                    results_df[\"Cluster ID\"].append(row[\"Cluster ID\"])\n",
    "                    results_df[\"Cluster Name\"].append(row[\"Cluster Name\"])\n",
    "                    results_df[\"Organism IDs\"].append(row[\"Organism IDs\"])\n",
    "                    results_df[\"Sequence\"].append(sequence)\n",
    "                    score = protein_to_scores[entry]\n",
    "                    for j,condensate in enumerate(OLDCOMPS):\n",
    "                        results_df[f\"{condensate.upper()}_Score\"].append(score[j].item())\n",
    "        tqdm_bar.update()\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e419f7ad-7eca-49b1-b8dc-ce88629911d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e91b80-eea0-4e87-97a9-201bd64d55ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"Condensate_data_idmapping_2023_11_04_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bed1d4-e924-412a-a9f5-d5899f25dcd7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Substitutions_set_230130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2c705c-cfd8-491e-8571-2bc2cea85fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"substitutions_set_230130.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a4f800-822c-4373-8e92-d6481eea4627",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f434fba9-b8c6-4874-a06d-27ebc5223204",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_valid_seq_len = get_valid_rows(data, ['WT_Sequence', 'Substitution_seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5950cee-f50a-4f56-ae4b-29a2e61e041f",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(rows_with_valid_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546b60d1-8c73-40ed-8888-9f2bba31019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[rows_with_valid_seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e5b3e5-20fa-4fbb-b3a6-2337c1b56fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "sequences = list(data['WT_Sequence'])\n",
    "scores = predict_condensates(model, sequences, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fadd4b-a6d6-4493-a30e-88ddf6675a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,condensate in enumerate(OLDCOMPS):\n",
    "    data[f\"WT_Sequence_{condensate.upper()}_Score\"] = scores[:, j].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1991b3db-be10-49e4-ac1c-07d37f32976d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "sequences = list(data['Substitution_seq'])\n",
    "scores = predict_condensates(model, sequences, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dfb911-0f72-4cd7-8717-3707f8aad14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,condensate in enumerate(OLDCOMPS):\n",
    "    data[f\"Substitution_seq_{condensate.upper()}_Score\"] = scores[:, j].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888f1f19-c683-451c-9def-6c010df762ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('substitutions_set_230130_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c2b597-9591-44fe-8e33-9a0c166187b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### termination_set_230129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a952cb1-2c00-4204-b75b-923ff7f0b9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"termination_set_230129.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34322ef-7d18-47ea-83ee-a6413da5d40f",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e903b33-d0e4-41d1-8ce2-53aaa411db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_valid_seq_len = get_valid_rows(data, ['WT_Sequence', 'Termination_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71df0e7c-9693-4841-9762-8fce562bb103",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[rows_with_valid_seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0b3839-358f-4bd5-89d3-0e1aa7511f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(rows_with_valid_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347fabc1-ea7f-4d61-b6fb-580cb8b1433e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "sequences = list(data['WT_Sequence'])\n",
    "scores = predict_condensates(model, sequences, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d9fe4c-b84a-4a28-ac2b-21d7498548a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,condensate in enumerate(OLDCOMPS):\n",
    "    data[f\"WT_Sequence_{condensate.upper()}_Score\"] = scores[:, j].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40062a23-4c2a-44b2-9791-4db02aedba3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "sequences = list(data['Termination_sequence'])\n",
    "scores = predict_condensates(model, sequences, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436eea28-31df-4774-bd22-709a58302292",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,condensate in enumerate(OLDCOMPS):\n",
    "    data[f\"Termination_sequence_{condensate.upper()}_Score\"] = scores[:, j].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e344ee-3d3c-4762-acfa-b2055475721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('termination_set_230129_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a970c51-f52e-43f8-a63e-5d98eef67cbc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### disease_mutations_reference_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f466094f-f049-4de4-be21-54d69a396b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"disease_mutations_reference_set.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e917fec-ca8d-4068-ad28-6a80d229d870",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f06764-d250-47ea-9c5d-591f9abbb6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_valid_seq_len = get_valid_rows(data, ['Sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2bd965-f84a-41e3-b8b9-808fac9c0be0",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(rows_with_valid_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7c74a9-bdaf-45ef-bf08-9bde77ec77d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[rows_with_valid_seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6590737f-0afa-4cf2-9249-8a7a7672b8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "sequences = [s.upper() for s in list(data['Sequence'])]\n",
    "scores = predict_condensates(model, sequences, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d394aec1-6849-47f6-9aae-e4693011bf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,condensate in enumerate(OLDCOMPS):\n",
    "    data[f\"{condensate.upper()}_Score\"] = scores[:, j].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1910e5b8-fec9-4639-8fd2-9b33aa0efcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('disease_mutations_reference_set_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f464b65b-9405-4c81-af55-67bc29b2c93c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a0a1748-9bbe-4c0a-a103-4b10a316864a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# AUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "080e4f08-5154-495f-b5fa-b25bd086dbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# args\n",
    "args = Namespace(**pickle.load(open(os.path.join(PROTGPS_PARENT_DIR, 'checkpoints/protgps/32bf44b16a4e770a674896b81dfb3729.args'),'rb')))\n",
    "args.dataset_file_path = os.path.join(PROTGPS_PARENT_DIR, \"data/new_condensate_dataset_m3_c5_mmseqs.json\")\n",
    "# Load test dataset\n",
    "test_dataset = get_object(args.dataset_name, \"dataset\")(args, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f788728-23ec-4eac-9b2a-6205d0672c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = [d['y'] for d in test_dataset.dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cf5bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(args)\n",
    "model = model[0]\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "191f1767-27fd-4b0b-9dde-04d3308edb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = [s['x'] for s in test_dataset.dataset]\n",
    "test_y = [transform_y(s['y']) for s in test_dataset.dataset]\n",
    "test_id = [s['entry_id'] for s in test_dataset.dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "417c966f-8b32-489c-ae20-772786051212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "test_preds = predict_condensates(model, test_x, 10, round=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ce5ed1cf-34e2-41bc-a522-a058a45a0aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = torch.vstack(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9e9af7ee-c76e-42e3-b805-8cfbd7e35294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "for j,condensate in enumerate(OLDCOMPS):\n",
    "    auc = roc_auc_score(test_y[:,j], test_preds[:,j])\n",
    "    print(f\"{condensate}:\\t{round(auc,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321c1c15-8474-4c64-b722-c94a87031a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3414a86-4eb1-44ac-bd99-3e1b095275c3",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9c31143-7603-4d14-8ee1-aac23b79710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_sequences = [\n",
    "    {\n",
    "        \"condensate\": \"nucleolus\",\n",
    "        \"name\": \"mc2_nuc1\",\n",
    "        \"seed\": 6,\n",
    "        \"sequence\": \"FMLVSTLWWKQKRLNNAVRTHTKFLTTINNPWRDFCSHRKKYCQKRKHEHATLKSWGTNNGSRRAAGICSGYGPEHSPDANTVKHCCIDYDSIDPIRCTR\"\n",
    "    },\n",
    "    {\n",
    "        \"condensate\": \"nucleolus\",\n",
    "        \"name\": \"mc2_nuc2\",\n",
    "        \"seed\": 1,\n",
    "        \"sequence\": \"HFMRIADRKVMHHGCAKQGNSWNHIGQKPCCSKVKKGEQSQKADAVVWGVKCHMKWEARSQCNQSFEKMQLHCPMSCRVQESSHNQHNIQPKANHQAMIH\"\n",
    "    },\n",
    "    {\n",
    "        \"condensate\": \"nucleolus\",\n",
    "        \"name\": \"mc2_nuc7\",\n",
    "        \"seed\": 7,\n",
    "        \"sequence\": \"HGQNRRRKNIGTLKMHTIRGFFPMFSEIRNNHTFTIHGSKSFNSDFQDQNLHCHDRMMHLQISDSMNNTGEEWMTEKVNSLPRKGKSGGPPYKPKVWSVQ\"\n",
    "    },\n",
    "    {\n",
    "        \"condensate\": \"nuclear_speckle\",\n",
    "        \"name\": \"mc2_spk2\",\n",
    "        \"seed\": 8,\n",
    "        \"sequence\": \"VNDITDVEMAVGRVPREGGNATERCYACFHHLDDYDLHQQMHGRDAPHMRNNSYKKAAHSEHINEVDHQGLQSDVEEYEGVMNEDTFKYMADERDCSPRN\"\n",
    "    },\n",
    "    {\n",
    "        \"condensate\": \"nuclear_speckle\",\n",
    "        \"name\": \"mc2_spk3\",\n",
    "        \"seed\": 7,\n",
    "        \"sequence\": \"TKIKKHRSTPNMIQSPVTYPDEDHTNNHAGWKTTKAAAPKFRCAARQINRTAMMRCENFAITIDDMPSQDWPHKDDHGAGDDKKDCMPARYDGHTEETND\"\n",
    "    },\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2139fb2-0e5d-4c94-95c2-6961f85eeda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcherry = 'LVQLVHAAGGVAALGAFVLFHDGVVLVVGKDVQLDVDVVGAGQLHGLLGLVGGLDLSVVVAAVLQLQPLLDLALQGAVLGVHPLSGGLPAHGTTLHYGAVGGEVGAAQLHLVDELAVLQGGVLGHGHHAAVLEVHHALPIEALGEGQLQVVGDVGGVLHVGLGAVHELRGQDVPGEGQGATLGHLQLGGLGALVGAALALALDLELVAVHGALHVHLEAHELLDDGHVILLALAH'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cb76a8-3176-4c4e-b3e1-895965229580",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Integrated Gradients | Attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8085b4e9-207d-4f78-b870-596123eb95cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_text(datarecords, legend: bool = True) -> \"HTML\":  # In quotes because this type doesn't exist in standalone mode\n",
    "    dom = [\"<table width: 100%>\"]\n",
    "    rows = [\n",
    "        #\"<tr><th>True Label</th>\"\n",
    "        #\"<th>Attribution Label</th>\"\n",
    "        #\"<th>Attribution Score</th>\"\n",
    "        \"<th>Amino Acid Importance</th>\" #\"<th>Word Importance</th>\"\n",
    "        \"<th>Sample ID</th>\"\n",
    "        \"<th>Target (score)</th>\"#\"<th>Predicted Label</th>\"\n",
    "    ]\n",
    "    for datarecord in datarecords:\n",
    "        rows.append(\n",
    "            \"\".join(\n",
    "                [\n",
    "                    \"<tr>\",\n",
    "                    # format_classname(datarecord.true_class),\n",
    "                    #format_classname(datarecord.attr_class),\n",
    "                    # format_classname(\"{0:.2f}\".format(datarecord.attr_score)),\n",
    "                    viz.format_word_importances(\n",
    "                        datarecord.raw_input_ids, datarecord.word_attributions\n",
    "                    ),\n",
    "                    viz.format_classname(datarecord.true_class.split('_')[1]),\n",
    "                    viz.format_classname(\n",
    "                        \"{0} ({1:.2f})\".format(\n",
    "                            datarecord.pred_class, datarecord.pred_prob\n",
    "                        )\n",
    "                    ),\n",
    "                    \n",
    "                    \"<tr>\",\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if legend:\n",
    "        dom.append(\n",
    "            '<div style=\"border-top: 1px solid; margin-top: 5px; \\\n",
    "            padding-top: 5px; display: inline-block\">'\n",
    "        )\n",
    "        dom.append(\"<b>Legend: </b>\")\n",
    "\n",
    "        for value, label in zip([-1, 0, 1], [\"Negative\", \"Neutral\", \"Positive\"]):\n",
    "            dom.append(\n",
    "                '<span style=\"display: inline-block; width: 10px; height: 10px; \\\n",
    "                border: 1px solid; background-color: \\\n",
    "                {value}\"></span> {label}  '.format(\n",
    "                    value=viz._get_color(value), label=label\n",
    "                )\n",
    "            )\n",
    "        dom.append(\"</div>\")\n",
    "\n",
    "    dom.append(\"\".join(rows))\n",
    "    dom.append(\"</table>\")\n",
    "    html = viz.HTML(\"\".join(dom))\n",
    "    viz.display(html)\n",
    "\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39117097-29ff-416a-8b2f-95dfa398c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(batch_tokens):\n",
    "    model.zero_grad()\n",
    "    result = model.model.encoder.model(batch_tokens, repr_layers = [model.model.encoder.repr_layer], return_contacts=False)\n",
    "    hidden = result[\"representations\"][model.model.encoder.repr_layer].mean(axis=1)\n",
    "    scores = torch.sigmoid(model.model.mlp({'x': hidden})[\"logit\"])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b90cc16-4622-4b5d-ba7e-232cc352658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed258f40-10fc-41f4-a8a1-0c71a5307d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = model.model.encoder.alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "134e6a61-55b0-473a-b347-ab1131ab6e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "lig = LayerIntegratedGradients(forward, model.model.encoder.model.embed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dc1ade46-9302-4fdf-98e9-77eb9e1f6465",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "sequence_dict_copy = copy.deepcopy(experimental_sequences)\n",
    "for sequence_dict in sequence_dict_copy:\n",
    "    seq = sequence_dict['sequence']\n",
    "    input_seq = seq +  mcherry\n",
    "\n",
    "    # baseline\n",
    "    baseline = torch.tensor([alphabet.cls_idx] + [alphabet.mask_idx] * len(input_seq) + [alphabet.eos_idx]).unsqueeze(0)\n",
    "\n",
    "    # inputs \n",
    "    fair_x = [(0, input_seq)] \n",
    "    _, _, batch_tokens = model.model.encoder.batch_converter(fair_x)\n",
    "\n",
    "    # get prediction\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        out = model.model({'x': [input_seq] })\n",
    "    probs = torch.sigmoid(out['logit']).detach().cpu()\n",
    "    pred_class = probs.argmax().item()\n",
    "    pred_class_name = OLDCOMPS[ pred_class ]\n",
    "\n",
    "    assert pred_class_name == sequence_dict[\"condensate\"]\n",
    "\n",
    "    # get attribution\n",
    "    attributions, delta = lig.attribute(\n",
    "            inputs=batch_tokens,\n",
    "            baselines=baseline,\n",
    "            return_convergence_delta=True,\n",
    "            target = pred_class,\n",
    "            n_steps=50,\n",
    "        )\n",
    "    A = attributions.sum(-1)[0, 1:-1]\n",
    "    A = A / torch.norm(A)\n",
    "    sequence_dict[\"attributions\"] = A.tolist()\n",
    "\n",
    "    # visualize\n",
    "    record = viz.VisualizationDataRecord(\n",
    "            word_attributions = A * 10,\n",
    "            pred_prob = probs.max().item(),\n",
    "            pred_class = pred_class_name,\n",
    "            true_class = sequence_dict[\"name\"],\n",
    "            attr_class = \"-\",\n",
    "            attr_score = attributions[0, 1:-1].sum(),\n",
    "            raw_input_ids= input_seq,\n",
    "            convergence_score = delta,\n",
    "        )\n",
    "    records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a951141a-486c-42f2-8e7c-eb0f24cf0050",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "html = visualize_text(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a5d1c9ec-8131-4592-abe3-ce8e6fc34014",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('html_file.html', 'w') as f:\n",
    "    f.write(html.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "95c3a4ba-378e-4d24-a057-30d1eb14493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sequence_dict in sequence_dict_copy:\n",
    "    seq = sequence_dict['sequence']\n",
    "    sequence_dict['full_sequence'] = seq +  mcherry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "16d48495-6d1b-47a1-8fae-f8d07c0adaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(sequence_dict_copy).to_csv('attributions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a713920b-7b97-4f6c-a01d-2b584d43ac1f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ff5a4fc-9c7c-4fdd-b85e-e306a05d077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "for root,_,files in os.walk(os.path.join(esm_directory, \"trajectories\")):\n",
    "    paths.extend([ os.path.join(root, f) for f in files if f.endswith('.txt')])\n",
    "\n",
    "\n",
    "idr2scores = defaultdict(list)\n",
    "preds = []\n",
    "for p in paths:\n",
    "    config = os.path.join(os.path.dirname(p), \".hydra/config.yaml\")\n",
    "    with open(config, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    condensate = p.split('/')[-1].split('.')[0]\n",
    "    with open(p, 'r') as f:\n",
    "        preds = f.readlines()\n",
    "    preds = [p.strip('\\n') for p in preds]\n",
    "    idr2scores[f\"{condensate}_{config['seed']}\"].extend([p.split('\\t') for p in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f093844-c7db-4727-9a8f-c161df9547b6",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idr2scores.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e5d07a9-1d80-4355-9eb7-c802db5b9539",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f494d6e-c5b9-4d13-bcc3-5249c99a9527",
   "metadata": {},
   "outputs": [],
   "source": [
    "for generated, traj in idr2scores.items():\n",
    "    \n",
    "    target, seed = generated[:-2], generated[-1]\n",
    "    trajectory = [(int(i.split(':')[0]), s, float(p)) for i,s,p in traj ]\n",
    "    trajectory = sorted(trajectory, key = lambda x: x[0])\n",
    "    \n",
    "    steps = [s[0] for s in trajectory]\n",
    "    seqs = [s[1] for s in trajectory]\n",
    "    scores = [s[2] for s in trajectory]\n",
    "    \n",
    "    trajectories[\"Target Compartment\"].extend( [target] * len(steps) )\n",
    "    trajectories[\"Seed\"].extend([seed] * len(steps))\n",
    "    trajectories[\"Step\"].extend(steps)\n",
    "    trajectories[\"IDR Sequence\"].extend(seqs)\n",
    "    trajectories[\"Localization Score\"].extend(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c63c113-49e6-4e27-8d8f-834aa18d1b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(trajectories).to_csv('trajectories.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "4ec952fd-c3ff-4104-b00b-4794145551a7",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( [i[0] for i in trajectory], [i[-1] for i in trajectory])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4817474e-f9ee-4d78-a327-4b6eb15f55ac",
   "metadata": {},
   "source": [
    "# Revisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4b449fd-720f-4198-8114-6dd7d9f48efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import MultiOutputClassifier, ClassifierChain\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1df9bb79-38cc-4fc5-b560-41e796ad7e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(sequence):\n",
    "    features = [protpy.amino_acid_composition(sequence)]\n",
    "    for key in [\"hydrophobicity\", \"polarity\", \"charge\", \"solvent_accessibility\", \"polarizability\"]:\n",
    "        features.extend([\n",
    "            protpy.ctd_composition(sequence, property=key),\n",
    "            protpy.ctd_transition(sequence, property=key),\n",
    "            protpy.ctd_distribution(sequence, property=key)\n",
    "        ])  \n",
    "    features = pd.concat(features, axis=1)\n",
    "    features = np.array(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cccf01-2fa4-4467-8209-f783059fe5ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Classic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "436f8366-1965-4a56-b5e2-839f7087ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(**pickle.load(open(os.path.join(PROTGPS_PARENT_DIR, 'checkpoints/protgps/32bf44b16a4e770a674896b81dfb3729.args'),'rb')))\n",
    "args.pretrained_hub_dir = \"/home/protgps/esm_models/esm2\"\n",
    "args.dataset_file_path = os.path.join(PROTGPS_PARENT_DIR, \"data/new_condensate_dataset_m3_c5_mmseqs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0cf3bd2-da42-4e21-a848-cabbe5de3e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "train_dataset = get_object(args.dataset_name, \"dataset\")(args, \"train\")\n",
    "dev_dataset = get_object(args.dataset_name, \"dataset\")(args, \"dev\")\n",
    "test_dataset = get_object(args.dataset_name, \"dataset\")(args, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "34b4bb62-802c-49a1-afb2-030616cfe448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "train_data_classic = []\n",
    "for sample in tqdm(train_dataset.dataset, ncols=100):\n",
    "    if any(k not in protpyAA for k in sample['x']):\n",
    "        continue\n",
    "    train_data_classic.append({\n",
    "        \"x\": make_features(sample['x']),\n",
    "        'y': sample['y'],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "29508cdd-3b6d-4704-908c-7c6c9d1dc319",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.concatenate([d['x'] for d in train_data_classic])\n",
    "trainY = np.stack([d['y'] for d in train_data_classic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "94b80947-defb-48fc-9867-4774440c9ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "test_data_classic = []\n",
    "for sample in tqdm(test_dataset.dataset, ncols=100):\n",
    "    if any(k not in protpyAA for k in sample['x']):\n",
    "        continue\n",
    "    test_data_classic.append({\n",
    "        \"x\": make_features(sample['x']),\n",
    "        'y': sample['y'],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "46ec0a65-c274-4274-ae38-de3469d23bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data_classic), len(test_dataset.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "662568f6-1b26-46ca-9281-b43afd1e4c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = np.concatenate([d['x'] for d in test_data_classic])\n",
    "testY = np.stack([d['y'] for d in test_data_classic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d6a2e588-03dd-4502-9d55-02789ad46b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "rf =  RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=400, \n",
    "    random_state=0, \n",
    ")\n",
    "\n",
    "multi_target_rf = ClassifierChain(rf)\n",
    "multi_target_rf.fit(trainX, trainY)\n",
    "predY = multi_target_rf.predict_proba(testX)\n",
    "\n",
    "for i, c in enumerate(OLDCOMPS):\n",
    "    auc = roc_auc_score(testY[:,i], predY[:,i])\n",
    "    print(f\"ROC-AUC {c}: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8afdd96a-7ea9-4a5b-916e-11b5ee401b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logreg =  LogisticRegression(solver=\"liblinear\", random_state=0)\n",
    "\n",
    "multi_target_lr = ClassifierChain(logreg)\n",
    "multi_target_lr.fit(trainX, trainY)\n",
    "predY = multi_target_lr.predict_proba(testX)\n",
    "\n",
    "for i, c in enumerate(OLDCOMPS):\n",
    "    auc = roc_auc_score(testY[:,i], predY[:,i])\n",
    "    print(f\"ROC-AUC {c}: {auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2598c0d0-16ff-49d8-855f-ac29f368dc5a",
   "metadata": {},
   "source": [
    "## MMSeqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "600ecbfb-b8a5-4115-b689-5dd5602cbbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(**pickle.load(open(os.path.join(PROTGPS_PARENT_DIR, 'checkpoints/protgps/7c4853cd22080b250ef89af2a1b25102.args'),'rb')))\n",
    "args.from_checkpoint = True\n",
    "args.checkpoint_path = os.path.join(PROTGPS_PARENT_DIR,\"checkpoints/protgps/7c4853cd22080b250ef89af2a1b25102epoch=3.ckpt\")\n",
    "args.model_path = args.checkpoint_path\n",
    "args.pretrained_hub_dir = \"/home/protgps/esm_models/esm2\"\n",
    "args.dataset_file_path = os.path.join(PROTGPS_PARENT_DIR, \"data/new_condensate_dataset_m3_c5_mmseqs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8bac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(args)\n",
    "model = model[0]\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "3f597c74-e592-4c46-972e-4cd5f1cb953f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "test_dataset = get_object(args.dataset_name, \"dataset\")(args, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "35edb2f9-49d5-4b62-ab1a-bb7b4c7455cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = [s['x'] for s in test_dataset.dataset]\n",
    "test_y = [s['y'] for s in test_dataset.dataset]\n",
    "test_id = [s['entry_id'] for s in test_dataset.dataset]\n",
    "test_y = torch.vstack(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "b55ce365-3753-493c-879e-3981bf28e47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "test_preds = predict_condensates(model, test_x, 1, round=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "1bc32ae8-f0cb-4956-87f3-545e2d0cddaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "for j,condensate in enumerate(OLDCOMPS):\n",
    "    auc = roc_auc_score(test_y[:,j], test_preds[:,j])\n",
    "    print(f\"{condensate}:\\t{round(auc,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e495d6d-53ea-49b9-80d4-d1bb8a8d1bfe",
   "metadata": {},
   "source": [
    "### classical models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a2530fd-fca1-41bc-8a36-a4e4eb8b5e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "train_dataset = get_object(args.dataset_name, \"dataset\")(args, \"train\")\n",
    "dev_dataset = get_object(args.dataset_name, \"dataset\")(args, \"dev\")\n",
    "test_dataset = get_object(args.dataset_name, \"dataset\")(args, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79fe2356-a094-4a0e-af03-86fb15a6bb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "train_data_classic = []\n",
    "for sample in tqdm(train_dataset.dataset, ncols=100):\n",
    "    if any(k not in protpyAA for k in sample['x']):\n",
    "        continue\n",
    "    train_data_classic.append({\n",
    "        \"x\": make_features(sample['x']),\n",
    "        'y': sample['y'],\n",
    "    })\n",
    "\n",
    "trainX = np.concatenate([d['x'] for d in train_data_classic])\n",
    "trainY = np.stack([d['y'] for d in train_data_classic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fe84d2c-ca33-4640-9a48-0aa166e03626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "test_data_classic = []\n",
    "for sample in tqdm(test_dataset.dataset, ncols=100):\n",
    "    if any(k not in protpyAA for k in sample['x']):\n",
    "        continue\n",
    "    test_data_classic.append({\n",
    "        \"x\": make_features(sample['x']),\n",
    "        'y': sample['y'],\n",
    "    })\n",
    "\n",
    "testX = np.concatenate([d['x'] for d in test_data_classic])\n",
    "testY = np.stack([d['y'] for d in test_data_classic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa387bed-a645-4d3e-8958-8daa44953568",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data_classic), len(test_dataset.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fb5eddc-c211-44f1-bac3-7867aa834adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "rf =  RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=400, \n",
    "    random_state=0, \n",
    ")\n",
    "\n",
    "multi_target_rf = ClassifierChain(rf)\n",
    "multi_target_rf.fit(trainX, trainY)\n",
    "predY = multi_target_rf.predict_proba(testX)\n",
    "\n",
    "for i, c in enumerate(OLDCOMPS):\n",
    "    auc = roc_auc_score(testY[:,i], predY[:,i])\n",
    "    print(f\"ROC-AUC {c}: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "153be311-27dc-44f7-b3a9-7edb428e879c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logreg =  LogisticRegression(solver=\"liblinear\", random_state=0)\n",
    "\n",
    "multi_target_lr = ClassifierChain(logreg)\n",
    "multi_target_lr.fit(trainX, trainY)\n",
    "predY = multi_target_lr.predict_proba(testX)\n",
    "\n",
    "for i, c in enumerate(OLDCOMPS):\n",
    "    auc = roc_auc_score(testY[:,i], predY[:,i])\n",
    "    print(f\"ROC-AUC {c}: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de2d5188-d373-4b09-8c4e-87275ea5b9db",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protpy.ctd_distribution(sample['x']).to_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protgps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
